{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project 01 : Discourse Markers Tagging.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hyE3zg6uefG"
      },
      "source": [
        "***Install Transformers in order to get the bert model with its tokenizer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JupAFaBuXga"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwPohshiukok"
      },
      "source": [
        "***Import the python modules***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX1iKn1yuqtg"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from transformers import FlaubertModel, FlaubertTokenizer\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import random\n",
        "import functools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzWdq5W0ut0j"
      },
      "source": [
        "***Set the seed value to ensure the reproducibility***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDtCU4uVu06I"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cjPJYSWu3qv"
      },
      "source": [
        "***Import the Bert tokenizer to represent the input and privde the same vocabulary that match the pretrained model vocab.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE56hTG2EUR6"
      },
      "source": [
        "# Choose among ['flaubert/flaubert_small_cased', 'flaubert/flaubert_base_uncased', \n",
        "#               'flaubert/flaubert_base_cased', 'flaubert/flaubert_large_cased']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHdZHpMQu3RK"
      },
      "source": [
        "from transformers import FlaubertTokenizer, FlaubertModel\n",
        "modelname = 'flaubert/flaubert_base_uncased' \n",
        "tokenizer = FlaubertTokenizer.from_pretrained(modelname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjFYsZboxrGk"
      },
      "source": [
        "***match the specific token such as [CLS] [PAD] [UNK] to those used in the pretrained model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boV9iTAoxqYz"
      },
      "source": [
        "init_token = tokenizer.cls_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, pad_token, unk_token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ot3P6SeyC4I"
      },
      "source": [
        "***integer representation of the specific tokens***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T47THsByOdk"
      },
      "source": [
        "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
        "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
        "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
        "\n",
        "print(init_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDSsS-gnyPfq"
      },
      "source": [
        "***Get the maximum length that the pretrained model was trained on***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsVgrWBDyX8D"
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes['flaubert/flaubert_base_uncased']\n",
        "print(max_input_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQZq3sRhydMf"
      },
      "source": [
        "***we'll define two helper functions that make use of our vocabulary.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo7fj4Dpya6v"
      },
      "source": [
        "def cut_and_convert_to_id(tokens, tokenizer, max_input_length):\n",
        "    tokens = tokens[:max_input_length-1] # cut the sequence of tokens to the desired maximum length (TEXT)\n",
        "    tokens = tokenizer.convert_tokens_to_ids(tokens) # convert the tokens into indexes\n",
        "    return tokens\n",
        "def cut_to_max_length(tokens, max_input_length):\n",
        "    tokens = tokens[:max_input_length-1] # cuts the sequence to the maximum length.(TAGS)\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v83juYqjzCID"
      },
      "source": [
        "***Create abstraction functions by the help of TorchText***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLljYPdgzIip"
      },
      "source": [
        "text_preprocessor = functools.partial(cut_and_convert_to_id,\n",
        "                                      tokenizer = tokenizer,\n",
        "                                      max_input_length = max_input_length)\n",
        "\n",
        "tag_preprocessor = functools.partial(cut_to_max_length,\n",
        "                                     max_input_length = max_input_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvo6aERB0DZv"
      },
      "source": [
        "***We define the FILEDS***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk158Q9g0Gmd"
      },
      "source": [
        "TEXT = data.Field(use_vocab = False,\n",
        "                  lower = True,\n",
        "                  preprocessing = text_preprocessor,\n",
        "                  init_token = init_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "UD_TAGS = data.Field(unk_token = None,\n",
        "                     init_token = '<pad>',\n",
        "                     preprocessing = tag_preprocessor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-67Y5nuM0HQs"
      },
      "source": [
        "***Match the fields to our data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0XQ1Ns90Lx3"
      },
      "source": [
        "fields = ((\"text\", TEXT), (\"udtags\", UD_TAGS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YM63nvhC0Nrm"
      },
      "source": [
        "***Load the data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0hgd4yn0M_I"
      },
      "source": [
        "class UDPOSFR(datasets.SequenceTaggingDataset):\n",
        "    # Universal Dependencies French Web Treebank.\n",
        "    # Download original at http://universaldependencies.org/\n",
        "    # License: http://creativecommons.org/licenses/by-sa/4.0/\n",
        "    urls = ['https://github.com/Dahouabdelhalim/udpos2/raw/main/data/fr-gsd-ud-15032020.zip'] # change to the dataset of your choice\n",
        "    dirname = 'fr-gsd-ud'  # don't forget to change me too !\n",
        "    name = 'udpos'         # not obligatory to change here\n",
        "\n",
        "    @classmethod\n",
        "    def splits(cls, fields, root=\".data\", \n",
        "               train=\"fr_gsd-ud-train.txt\",\n",
        "               validation=\"fr_gsd-ud-dev.txt\",\n",
        "               test=\"fr_gsd-ud-test.txt\", **kwargs):\n",
        "        \"\"\"Downloads and loads the Universal Dependencies Version 2 POS Tagged\n",
        "        data.\n",
        "        \"\"\"\n",
        "\n",
        "        return super(UDPOSFR, cls).splits(\n",
        "            fields=fields, root=root, train=train, validation=validation,\n",
        "            test=test, **kwargs)\n",
        "\n",
        "train_data, valid_data, test_data = UDPOSFR.splits(fields)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xydD7SLa0ch6"
      },
      "source": [
        "***Example from the data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf7T14lY0hwP"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZR7vph-06XL"
      },
      "source": [
        "***Build tags Vocab with the help of filed funciton***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0qS_y1g0_vO"
      },
      "source": [
        "UD_TAGS.build_vocab(train_data)\n",
        "\n",
        "print(UD_TAGS.vocab.stoi)\n",
        "len(UD_TAGS.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVPqoi1x1NwY"
      },
      "source": [
        "***Define our iterators (batch sizes and Device)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI3Omv2f1TGO"
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0eu8oeN2xoO"
      },
      "source": [
        "build the Model : The model is relatively simple, with all of the complicated parts contained inside the BERT module which we do not have to worry about. We can think of the BERT as an embedding layer and all we do is add a linear layer on top of these embeddings to predict the tag for each token in the input sequence.\n",
        "![ARCHITECUTRE.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVTy_qKa3Q1x"
      },
      "source": [
        "class BERTPoSTagger(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 output_dim, \n",
        "                 dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert\n",
        "        \n",
        "        embedding_dim = bert.config.to_dict()['emb_dim']\n",
        "        \n",
        "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "  \n",
        "        #text = [sent len, batch size]\n",
        "    \n",
        "        text = text.permute(1, 0) # Because bert get the batch size first\n",
        "        \n",
        "        #text = [batch size, sent len]\n",
        "        \n",
        "        embedded = self.dropout(self.bert(text)[0])\n",
        "        \n",
        "        #embedded = [batch size, seq len, emb dim]\n",
        "                \n",
        "        embedded = embedded.permute(1, 0, 2)\n",
        "                    \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        predictions = self.fc(self.dropout(embedded))\n",
        "        \n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "        \n",
        "        return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82yt3bGi3ggD"
      },
      "source": [
        "***Load the Pretrained BERT model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhw2jlH83mQt"
      },
      "source": [
        "flaubert, log = FlaubertModel.from_pretrained(modelname, output_loading_info=True ,output_hidden_states=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MuwZ7-87caz"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(flaubert):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIUIE6dMTYSW"
      },
      "source": [
        "***Freeze Model Parameters***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5AOcMel4gWm"
      },
      "source": [
        "***Instantiate the Hyperparameters and the Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuWs3ZXQ4l12"
      },
      "source": [
        "OUTPUT_DIM = len(UD_TAGS.vocab) # the dim of the output is the number of tags\n",
        "DROPOUT = 0.25\n",
        "LEARNING_RATE = 0.005 # lower learning rate to not fall on the catastrophic forgeting issue\n",
        "model = BERTPoSTagger(flaubert,OUTPUT_DIM, DROPOUT)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE) # specify the optimizer\n",
        "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX) # ignore the firt token on the tag representation \n",
        "\n",
        "model = model.to(device) # place the model on the Gpu if we have it \n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmtr1MH2CR1D"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYSXCbiu58lh"
      },
      "source": [
        "***Function that calculate the accuracy per batch***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWz4Pjvi6AYW"
      },
      "source": [
        "def categorical_accuracy(preds, y, tag_pad_idx):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
        "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
        "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]]).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC8e0AHO6FYo"
      },
      "source": [
        "***We then define our train and evaluate functions to train and test our model.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBALOr3K6ZnB"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        text = batch.text\n",
        "        tags = batch.udtags\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        predictions = model(text)\n",
        "        \n",
        "        #predictions = [sent len, batch size, output dim]\n",
        "        #tags = [sent len, batch size]\n",
        "        \n",
        "        predictions = predictions.view(-1, predictions.shape[-1])\n",
        "        tags = tags.view(-1)\n",
        "        \n",
        "        #predictions = [sent len * batch size, output dim]\n",
        "        #tags = [sent len * batch size]\n",
        "        \n",
        "        loss = criterion(predictions, tags)\n",
        "                \n",
        "        acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr3P9HTa6fFJ"
      },
      "source": [
        "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text = batch.text\n",
        "            tags = batch.udtags\n",
        "            \n",
        "            predictions = model(text)\n",
        "            \n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = tags.view(-1)\n",
        "            \n",
        "            loss = criterion(predictions, tags)\n",
        "            \n",
        "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBcteZ0f6hku"
      },
      "source": [
        "***Helper functions to see how much each epoch took time***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaFfd5T26nzf"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27uJ_Ves6wWr"
      },
      "source": [
        "***Start the training and validation loop***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo-225SB6usk"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QlRVDBF7Lcv"
      },
      "source": [
        "***Loading the trained model and test it on test data***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLk56Dxq7Huf"
      },
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbmmUHB5UR-s"
      },
      "source": [
        "for name, param in flaubert.named_parameters():\n",
        "\tif 'classifier' not in name: # classifier layer\n",
        "\t\tparam.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD0qBLHp7olR"
      },
      "source": [
        "***Inference Function***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzj7Dn2Z7nOY"
      },
      "source": [
        "def tag_sentence(model, device, sentence, tokenizer, text_field, tag_field):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    if isinstance(sentence, str):\n",
        "        tokens = tokenizer.tokenize(sentence)\n",
        "    else:\n",
        "        tokens = sentence\n",
        "    \n",
        "    numericalized_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    numericalized_tokens = [text_field.init_token] + numericalized_tokens\n",
        "        \n",
        "    unk_idx = text_field.unk_token\n",
        "    \n",
        "    unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]\n",
        "    \n",
        "    token_tensor = torch.LongTensor(numericalized_tokens)\n",
        "    \n",
        "    token_tensor = token_tensor.unsqueeze(-1).to(device)\n",
        "         \n",
        "    predictions = model(token_tensor)\n",
        "    \n",
        "    top_predictions = predictions.argmax(-1)\n",
        "    \n",
        "    predicted_tags = [tag_field.vocab.itos[t.item()] for t in top_predictions]\n",
        "    \n",
        "    predicted_tags = predicted_tags[1:]\n",
        "        \n",
        "    assert len(tokens) == len(predicted_tags)\n",
        "    \n",
        "    return tokens, predicted_tags, unks\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvU_4rCS8ACY"
      },
      "source": [
        "***Run an example on a sentence***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO1Zs_GY775Y"
      },
      "source": [
        "sentence = 'tu mange.'\n",
        "tokens, tags, unks = tag_sentence(model, \n",
        "                                  device, \n",
        "                                  sentence,\n",
        "                                  tokenizer,\n",
        "                                  TEXT, \n",
        "                                  UD_TAGS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X2TIi_178SM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa48ec3-dd9c-4e9c-ffb5-638094baa724"
      },
      "source": [
        "print(\"Pred. Tag\\tToken\\n\")\n",
        "\n",
        "for token, tag in zip(tokens, tags):\n",
        "    print(f\"{tag}\\t\\t{token}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred. Tag\tToken\n",
            "\n",
            "PRON\t\ttu</w>\n",
            "PRON\t\tmange</w>\n",
            "PRON\t\t.</w>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH8QNUHA1oKv"
      },
      "source": [
        "***In the event that we want freeze the parameters, the following loop is used.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVs_-qeHdMmI"
      },
      "source": [
        "for name, param in flaubert.named_parameters():\n",
        "\tif 'classifier' not in name: # classifier layer\n",
        "\t\tparam.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}